---
description: Patterns for managing inter-code dependencies in GitHub Actions workflows during single production workflow generation.
alwaysApply: false
---

## Dependency Types

**CRITICAL**: There are TWO types of dependencies that require different job dependency patterns:

1. **Artifact Dependency**: Code type A needs an artifact from code type B's build job

   - Example: Terraform needs Lambda zip file from Python build
   - Job dependency: `A-deploy` needs `B-build` (NOT `B-deploy`)

2. **Infrastructure Dependency**: Code type A's deploy needs infrastructure created by code type B's deploy
   - Example: Python deploy needs Lambda function to exist (created by Terraform deploy)
   - Job dependency: `A-deploy` needs `B-deploy`

## Single Dependency Pattern - Artifact Dependency

**When Code Type A needs an artifact from Code Type B** (e.g., Terraform needs Python Lambda package):

### Upstream Job (Code Type B - Python Build)

- Build and package artifacts (e.g., Lambda zip file)
- Upload artifacts using `actions/upload-artifact@v4`:
  ```yaml
  - name: Upload Lambda package
    uses: actions/upload-artifact@v4
    with:
      name: lambda-package
      path: lambda-package.zip
      retention-days: 1
  ```

### Downstream Job (Code Type A - Terraform Deploy)

- **CRITICAL**: Configure job dependency using `needs:` to wait for upstream **build job** (NOT deploy job):
  ```yaml
  terraform-deploy:
  needs: [terraform-lint, terraform-security, terraform-validate, python-build]
  runs-on: ubuntu-latest
  environment: production
  steps:
    - uses: actions/checkout@v4
  ```
- **CRITICAL**: Download artifacts from upstream build job BEFORE any Terraform operations (with error handling):

  ```yaml
  - name: Download Lambda package from Python build job
    uses: actions/download-artifact@v4
    continue-on-error: true
    id: download-artifact
    with:
      name: lambda-package
      path: ./lambda-package

  - name: Verify artifact downloaded successfully
    if: steps.download-artifact.outcome != 'success'
    run: |
      echo "Error: Failed to download artifact 'lambda-package' from Python build job"
      exit 1
  ```

- **Place artifact in correct location** where Terraform expects it:
  ```yaml
  - name: Move Lambda package to Terraform directory
    run: |
      # CRITICAL: Check the actual path referenced in Terraform code
      # If Terraform uses: filename = "lambda_function.zip" in the same directory
      # Place it where Terraform expects it (e.g., iac/terraform/lambda_function.zip)
      mkdir -p ./iac/terraform
      cp ./lambda-package/lambda-package.zip ./iac/terraform/lambda_function.zip
      # Adjust path based on actual Terraform code location and filename
      echo "TF_VAR_lambda_package_path=$(pwd)/iac/terraform/lambda_function.zip" >> $GITHUB_ENV
  ```
- **Verify artifact exists** before Terraform operations:
  ```yaml
  - name: Verify Lambda package exists
    run: |
      # Verify the exact path that Terraform code references
      TERRAFORM_LAMBDA_PATH="./iac/terraform/lambda_function.zip"
      if [ ! -f "$TERRAFORM_LAMBDA_PATH" ]; then
        echo "Error: Lambda package not found at: $TERRAFORM_LAMBDA_PATH"
        echo "Downloaded artifacts location:"
        ls -la ./lambda-package/ || echo "lambda-package directory not found"
        exit 1
      fi
      echo "✓ Lambda package verified at: $TERRAFORM_LAMBDA_PATH"
  ```
- **Order of operations**: Checkout → Download artifacts → Place artifacts → Verify artifacts → Configure credentials → Terraform init/plan/apply

---

## Combined Dependencies Pattern (Artifact + Infrastructure)

**When a code type has both artifact and infrastructure dependencies** (e.g., Terraform needs Python artifact, Python deploy needs Terraform infrastructure):

```yaml
# Terraform deploy needs Python build artifact
terraform-deploy:
  needs: [terraform-lint, terraform-security, terraform-validate, python-build]
  runs-on: ubuntu-latest
  environment: production
  steps:
    - uses: actions/checkout@v4
    - name: Download Lambda package from Python build
      uses: actions/download-artifact@v4
      with:
        name: lambda-package
        path: ./lambda-package
    # ... Terraform deployment steps

# Python deploy needs Terraform to create Lambda function first
python-deploy:
  needs: [python-build, terraform-deploy]
  runs-on: ubuntu-latest
  environment: production
  steps:
    - uses: actions/checkout@v4
    - name: Download Lambda package
      uses: actions/download-artifact@v4
      with:
        name: lambda-package
    # ... Python deployment steps (updates Lambda function code)
```

**Execution Order**:

1. Python build → produces artifact
2. Terraform deploy → uses Python artifact, creates Lambda function
3. Python deploy → updates Lambda function code (function must exist)

## Multiple Dependencies Pattern

If a code type depends on multiple others, configure job dependencies using `needs:` to wait for all required upstream jobs (build jobs for artifacts, deploy jobs for infrastructure):

```yaml
kubernetes-deploy:
needs:
  [
    kubernetes-lint,
    kubernetes-security,
    kubernetes-validate,
    python-deploy,
    docker-deploy,
  ]
runs-on: ubuntu-latest
environment: production
steps:
  - uses: actions/checkout@v4
  # Download artifacts from all upstream build jobs
  - name: Download Lambda package from Python build
    uses: actions/download-artifact@v4
    with:
      name: lambda-package
      path: ./lambda-package
  - name: Download Docker image info from Docker build
    uses: actions/download-artifact@v4
    with:
      name: docker-image
      path: ./docker-image
```

**Important**: When multiple dependencies exist, download artifacts from all upstream build jobs. Each build job uploads its artifacts independently, so you can download them all in the downstream deploy job.

---

## Artifact Passing Methods

**For Unified Workflow**: All artifact passing happens within the same workflow using GitHub Actions artifacts.

### Method 1: GitHub Actions Artifacts (MANDATORY for unified workflow)

- Use `actions/upload-artifact@v4` in build jobs
- Use `actions/download-artifact@v4` in deploy jobs
- Works within same workflow run (jobs in same workflow)
- Limited retention (default 1 day, configurable up to 90 days)
- **This is the ONLY method needed for unified workflow architecture**

**Pattern**:

1. **Build Job** (upstream): Upload artifact

   ```yaml
   python-build:
     needs: [python-lint, python-security, python-test]
     steps:
       - name: Upload Lambda package
         uses: actions/upload-artifact@v4
         with:
           name: lambda-package
           path: lambda-package.zip
   ```

2. **Deploy Job** (downstream): Download artifact
   ```yaml
   terraform-deploy:
     needs:
       [terraform-lint, terraform-security, terraform-validate, python-build]
     steps:
       - name: Download Lambda package
         uses: actions/download-artifact@v4
         with:
           name: lambda-package
           path: ./lambda-package
   ```

## Single Dependency Pattern - Infrastructure Dependency

**When Code Type A's deploy needs infrastructure created by Code Type B's deploy** (e.g., Python deploy needs Lambda function created by Terraform):

### Upstream Job (Code Type B - Terraform Deploy)

- Creates infrastructure resources (e.g., Lambda function, S3 bucket, etc.)
- Infrastructure must exist before downstream deploy can update/use it

### Downstream Job (Code Type A - Python Deploy)

- **CRITICAL**: Configure job dependency using `needs:` to wait for upstream **deploy job**:
  ```yaml
  python-deploy:
  needs: [python-build, terraform-deploy]
  runs-on: ubuntu-latest
  environment: production
  steps:
    - uses: actions/checkout@v4
    - name: Configure AWS credentials via OIDC
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
        aws-region: ${{ vars.AWS_REGION }}
    - name: Download Lambda package
      uses: actions/download-artifact@v4
      with:
        name: lambda-package
    - name: Deploy Lambda function
      run: |
        # Lambda function must exist (created by Terraform) before updating code
        aws lambda update-function-code \
          --function-name s3-lambda-trigger-hello-world \
          --zip-file fileb://lambda-package/lambda-package.zip || \
        aws lambda create-function \
          --function-name s3-lambda-trigger-hello-world \
          --runtime python3.12 \
          --role ${{ secrets.AWS_LAMBDA_ROLE_ARN }} \
          --handler lambda_handler.lambda_handler \
          --zip-file fileb://lambda-package/lambda-package.zip \
          --memory-size 128
  ```

**Key Points**:

- Infrastructure dependency means the resource must exist before deploy
- Wait for upstream deploy job, not build job
- Common pattern: Application code deploy needs infrastructure to exist first

### Alternative Methods (Only if needed for special cases)

### Method 2: S3/Storage (For long retention or external access)

- Upload to S3 bucket with predictable naming
- Download from S3 in deploy job
- Use when: Artifacts need longer retention OR external systems need access

### Method 3: Container Registry (For Docker images)

- Push Docker images with tags to registry (ECR, Docker Hub, etc.)
- Reference image tags in deploy jobs
- Use when: Artifact is a Docker/container image

### Method 4: Environment Variables/Job Outputs (For artifact metadata)

- Pass artifact paths/URLs via job outputs
- Use when: Only artifact location/URL needs to be passed (not the artifact itself)

---

## Single Production Workflow Considerations

- Artifact names should be simple and consistent: `lambda-package` (no environment suffix)
- Workflow trigger: `push` to `main` branch only and `workflow_dispatch` for manual execution
- Use appropriate retention for artifacts (1-7 days typically sufficient)
- All deploy jobs use `environment: production` (single production environment)
- Job dependencies (`needs:`) enforce execution order
- Artifacts are passed between jobs in the same workflow (no cross-workflow downloads needed)

---

## Best Practices

1. **Always verify artifacts exist** before using them in deployment steps
2. **Use consistent artifact naming** to avoid conflicts
3. **Handle errors gracefully** with `continue-on-error` and verification steps
4. **Document artifact paths** in workflow comments for maintainability
5. **Use S3/Storage for multiple dependencies** to avoid complexity
6. **Test artifact passing** before deployment

---

## Troubleshooting

- **Artifact not found**: Check artifact name matches exactly (case-sensitive) between upload and download
- **Download fails**: Verify artifact was uploaded in upstream build job and job dependency (`needs:`) is correct
- **Path mismatch**: Verify artifact is placed where deployment code expects it
- **Job runs before dependency**: Verify `needs:` array includes all required upstream jobs
- **Multiple dependencies**: Download all artifacts from their respective build jobs in the deploy job

See `workflow-common-issues.mdc` for more troubleshooting guidance.
